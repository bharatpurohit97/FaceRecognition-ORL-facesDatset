{"cells":[{"cell_type":"code","source":["import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import TensorBoard\n\nimport numpy as np\nimport pandas as pd\n\nfrom keras.utils import np_utils\nimport itertools\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import accuracy_score"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["data = np.load('/dbfs/FileStore/tables/ORL_faces.npz') \n\nx_train = data['trainX']\n#normalize every image\nx_train = np.array(x_train,dtype='float32')/255\n\nx_test = data['testX']\nx_test = np.array(x_test,dtype='float32')/255\n\n# load the Label of Images\ny_train= data['trainY']\ny_test= data['testY']\n\n# show the train and test Data format\nprint('x_train : {}'.format(x_train[:]))\nprint('Y-train shape: {}'.format(y_train))\nprint('x_test shape: {}'.format(x_test.shape))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">x_train : [[0.1882353  0.19215687 0.1764706  ... 0.18431373 0.18039216 0.18039216]\n [0.23529412 0.23529412 0.24313726 ... 0.1254902  0.13333334 0.13333334]\n [0.15294118 0.17254902 0.20784314 ... 0.11372549 0.10196079 0.11372549]\n ...\n [0.44705883 0.45882353 0.44705883 ... 0.38431373 0.3764706  0.38431373]\n [0.4117647  0.4117647  0.41960785 ... 0.21176471 0.18431373 0.16078432]\n [0.45490196 0.44705883 0.45882353 ... 0.37254903 0.39215687 0.39607844]]\nY-train shape: [ 0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  1  1\n  2  2  2  2  2  2  2  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3  3  3\n  4  4  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5\n  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  7  7\n  8  8  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9\n 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11\n 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13\n 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15\n 16 16 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17\n 18 18 18 18 18 18 18 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 19 19]\nx_test shape: (160, 10304)\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["x_train, x_valid, y_train, y_valid= train_test_split(\n    x_train, y_train, test_size=.05, random_state=1234,)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["im_rows=112\nim_cols=92\nbatch_size=512\nim_shape=(im_rows, im_cols, 1)\n\n#change the size of images\nx_train = x_train.reshape(x_train.shape[0], *im_shape)\nx_test = x_test.reshape(x_test.shape[0], *im_shape)\nx_valid = x_valid.reshape(x_valid.shape[0], *im_shape)\n\nprint('x_train shape: {}'.format(y_train.shape[0]))\nprint('x_test shape: {}'.format(y_test.shape))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">x_train shape: 228\nx_test shape: (160,)\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["cnn_model= Sequential([\n    Conv2D(filters=36, kernel_size=7, activation='relu', input_shape= im_shape),\n    MaxPooling2D(pool_size=2),\n    Conv2D(filters=54, kernel_size=5, activation='relu', input_shape= im_shape),\n    MaxPooling2D(pool_size=2),\n    Flatten(),\n    Dense(2024, activation='relu'),\n     Dropout(0.5),\n    Dense(1024, activation='relu'),\n    Dropout(0.5),\n    Dense(512, activation='relu'),\n    Dropout(0.5),\n    #20 is the number of outputs\n    Dense(20, activation='softmax')  \n])\n\ncnn_model.compile(\n    loss='sparse_categorical_crossentropy',#'categorical_crossentropy',\n    optimizer=Adam(lr=0.0001),\n    metrics=['accuracy']\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["cnn_model.summary()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 106, 86, 36)       1800      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 53, 43, 36)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 49, 39, 54)        48654     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 24, 19, 54)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 24624)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 2024)              49841000  \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 2024)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1024)              2073600   \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 20)                10260     \n=================================================================\nTotal params: 52,500,114\nTrainable params: 52,500,114\nNon-trainable params: 0\n_________________________________________________________________\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["history=cnn_model.fit(\n    np.array(x_train), np.array(y_train), batch_size=512,\n    epochs=250, verbose=2,\n    validation_data=(np.array(x_valid),np.array(y_valid)),\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Train on 228 samples, validate on 12 samples\nEpoch 1/250\n - 6s - loss: 3.0150 - acc: 0.0526 - val_loss: 3.0079 - val_acc: 0.0833\nEpoch 2/250\n - 3s - loss: 2.9981 - acc: 0.0526 - val_loss: 3.0233 - val_acc: 0.0833\nEpoch 3/250\n - 3s - loss: 3.0197 - acc: 0.0482 - val_loss: 3.0230 - val_acc: 0.0000e+00\nEpoch 4/250\n - 3s - loss: 3.0064 - acc: 0.0746 - val_loss: 3.0320 - val_acc: 0.0000e+00\nEpoch 5/250\n - 3s - loss: 2.9687 - acc: 0.0965 - val_loss: 3.0324 - val_acc: 0.0000e+00\nEpoch 6/250\n - 4s - loss: 2.9784 - acc: 0.0789 - val_loss: 3.0279 - val_acc: 0.0000e+00\nEpoch 7/250\n - 3s - loss: 2.9924 - acc: 0.0658 - val_loss: 3.0228 - val_acc: 0.0000e+00\nEpoch 8/250\n - 4s - loss: 2.9842 - acc: 0.0658 - val_loss: 3.0178 - val_acc: 0.0000e+00\nEpoch 9/250\n - 3s - loss: 2.9839 - acc: 0.0833 - val_loss: 3.0161 - val_acc: 0.0000e+00\nEpoch 10/250\n - 4s - loss: 2.9664 - acc: 0.0614 - val_loss: 3.0132 - val_acc: 0.0000e+00\nEpoch 11/250\n - 3s - loss: 2.9650 - acc: 0.0526 - val_loss: 3.0117 - val_acc: 0.0000e+00\nEpoch 12/250\n - 4s - loss: 2.9652 - acc: 0.0921 - val_loss: 3.0102 - val_acc: 0.0000e+00\nEpoch 13/250\n - 4s - loss: 2.9718 - acc: 0.0658 - val_loss: 3.0087 - val_acc: 0.0000e+00\nEpoch 14/250\n - 6s - loss: 2.9691 - acc: 0.0833 - val_loss: 3.0037 - val_acc: 0.0000e+00\nEpoch 15/250\n - 6s - loss: 2.9480 - acc: 0.0965 - val_loss: 2.9977 - val_acc: 0.0000e+00\nEpoch 16/250\n - 4s - loss: 2.9371 - acc: 0.1096 - val_loss: 2.9924 - val_acc: 0.0000e+00\nEpoch 17/250\n - 4s - loss: 2.9149 - acc: 0.1272 - val_loss: 2.9866 - val_acc: 0.0000e+00\nEpoch 18/250\n - 3s - loss: 2.9315 - acc: 0.1316 - val_loss: 2.9820 - val_acc: 0.0000e+00\nEpoch 19/250\n - 3s - loss: 2.9256 - acc: 0.1228 - val_loss: 2.9788 - val_acc: 0.0000e+00\nEpoch 20/250\n - 3s - loss: 2.9088 - acc: 0.1535 - val_loss: 2.9761 - val_acc: 0.0000e+00\nEpoch 21/250\n - 4s - loss: 2.8989 - acc: 0.1447 - val_loss: 2.9737 - val_acc: 0.0000e+00\nEpoch 22/250\n - 3s - loss: 2.8860 - acc: 0.1711 - val_loss: 2.9704 - val_acc: 0.0000e+00\nEpoch 23/250\n - 4s - loss: 2.8786 - acc: 0.1623 - val_loss: 2.9652 - val_acc: 0.0000e+00\nEpoch 24/250\n - 3s - loss: 2.8832 - acc: 0.1272 - val_loss: 2.9575 - val_acc: 0.0000e+00\nEpoch 25/250\n - 4s - loss: 2.8693 - acc: 0.1447 - val_loss: 2.9473 - val_acc: 0.0000e+00\nEpoch 26/250\n - 3s - loss: 2.8528 - acc: 0.1754 - val_loss: 2.9330 - val_acc: 0.0000e+00\nEpoch 27/250\n - 3s - loss: 2.7948 - acc: 0.2281 - val_loss: 2.9167 - val_acc: 0.0000e+00\nEpoch 28/250\n - 3s - loss: 2.7801 - acc: 0.1711 - val_loss: 2.8979 - val_acc: 0.0833\nEpoch 29/250\n - 3s - loss: 2.7693 - acc: 0.2544 - val_loss: 2.8764 - val_acc: 0.0833\nEpoch 30/250\n - 4s - loss: 2.7891 - acc: 0.1535 - val_loss: 2.8479 - val_acc: 0.0833\nEpoch 31/250\n - 4s - loss: 2.7271 - acc: 0.2237 - val_loss: 2.8234 - val_acc: 0.0833\nEpoch 32/250\n - 4s - loss: 2.7560 - acc: 0.2018 - val_loss: 2.7969 - val_acc: 0.0833\nEpoch 33/250\n - 3s - loss: 2.7061 - acc: 0.2544 - val_loss: 2.7663 - val_acc: 0.1667\nEpoch 34/250\n - 3s - loss: 2.6489 - acc: 0.2763 - val_loss: 2.7314 - val_acc: 0.1667\nEpoch 35/250\n - 3s - loss: 2.6140 - acc: 0.2719 - val_loss: 2.6905 - val_acc: 0.1667\nEpoch 36/250\n - 4s - loss: 2.6357 - acc: 0.2632 - val_loss: 2.6480 - val_acc: 0.1667\nEpoch 37/250\n - 3s - loss: 2.5711 - acc: 0.2763 - val_loss: 2.6067 - val_acc: 0.2500\nEpoch 38/250\n - 3s - loss: 2.5515 - acc: 0.2719 - val_loss: 2.5660 - val_acc: 0.2500\nEpoch 39/250\n - 3s - loss: 2.5266 - acc: 0.3158 - val_loss: 2.5251 - val_acc: 0.2500\nEpoch 40/250\n - 3s - loss: 2.3940 - acc: 0.3904 - val_loss: 2.4771 - val_acc: 0.4167\nEpoch 41/250\n - 5s - loss: 2.3730 - acc: 0.3596 - val_loss: 2.4303 - val_acc: 0.4167\nEpoch 42/250\n - 3s - loss: 2.3219 - acc: 0.3816 - val_loss: 2.3866 - val_acc: 0.3333\nEpoch 43/250\n - 3s - loss: 2.2418 - acc: 0.3991 - val_loss: 2.3310 - val_acc: 0.2500\nEpoch 44/250\n - 3s - loss: 2.2465 - acc: 0.3684 - val_loss: 2.2714 - val_acc: 0.3333\nEpoch 45/250\n - 3s - loss: 2.2170 - acc: 0.3465 - val_loss: 2.2120 - val_acc: 0.3333\nEpoch 46/250\n - 4s - loss: 2.1561 - acc: 0.3991 - val_loss: 2.1537 - val_acc: 0.4167\nEpoch 47/250\n - 4s - loss: 2.1103 - acc: 0.3640 - val_loss: 2.0893 - val_acc: 0.4167\nEpoch 48/250\n - 4s - loss: 2.0436 - acc: 0.4298 - val_loss: 2.0293 - val_acc: 0.5000\nEpoch 49/250\n - 4s - loss: 1.9847 - acc: 0.4518 - val_loss: 1.9631 - val_acc: 0.5000\nEpoch 50/250\n - 4s - loss: 1.9992 - acc: 0.3816 - val_loss: 1.8936 - val_acc: 0.5000\nEpoch 51/250\n - 3s - loss: 1.8782 - acc: 0.4561 - val_loss: 1.8291 - val_acc: 0.5000\nEpoch 52/250\n - 3s - loss: 1.8826 - acc: 0.4518 - val_loss: 1.7635 - val_acc: 0.5000\nEpoch 53/250\n - 3s - loss: 1.7341 - acc: 0.4825 - val_loss: 1.7014 - val_acc: 0.5833\nEpoch 54/250\n - 3s - loss: 1.6133 - acc: 0.5439 - val_loss: 1.6317 - val_acc: 0.5833\nEpoch 55/250\n - 4s - loss: 1.7321 - acc: 0.5000 - val_loss: 1.5479 - val_acc: 0.7500\nEpoch 56/250\n - 4s - loss: 1.6124 - acc: 0.5088 - val_loss: 1.4796 - val_acc: 0.7500\nEpoch 57/250\n - 4s - loss: 1.5749 - acc: 0.5614 - val_loss: 1.4084 - val_acc: 0.7500\nEpoch 58/250\n - 4s - loss: 1.4486 - acc: 0.5702 - val_loss: 1.3370 - val_acc: 0.8333\nEpoch 59/250\n - 4s - loss: 1.4751 - acc: 0.5877 - val_loss: 1.2695 - val_acc: 0.9167\nEpoch 60/250\n - 3s - loss: 1.3613 - acc: 0.5789 - val_loss: 1.1900 - val_acc: 0.9167\nEpoch 61/250\n - 4s - loss: 1.3875 - acc: 0.5965 - val_loss: 1.0978 - val_acc: 1.0000\nEpoch 62/250\n - 4s - loss: 1.2160 - acc: 0.6667 - val_loss: 1.0222 - val_acc: 1.0000\nEpoch 63/250\n - 4s - loss: 1.1354 - acc: 0.6447 - val_loss: 0.9553 - val_acc: 1.0000\nEpoch 64/250\n - 6s - loss: 1.2163 - acc: 0.6272 - val_loss: 0.8963 - val_acc: 1.0000\nEpoch 65/250\n - 7s - loss: 1.1578 - acc: 0.6667 - val_loss: 0.8400 - val_acc: 1.0000\nEpoch 66/250\n - 4s - loss: 1.0783 - acc: 0.6842 - val_loss: 0.7851 - val_acc: 1.0000\nEpoch 67/250\n - 3s - loss: 1.0840 - acc: 0.6667 - val_loss: 0.7301 - val_acc: 1.0000\nEpoch 68/250\n - 4s - loss: 0.9948 - acc: 0.6842 - val_loss: 0.6828 - val_acc: 1.0000\nEpoch 69/250\n - 3s - loss: 0.9739 - acc: 0.7500 - val_loss: 0.6361 - val_acc: 1.0000\nEpoch 70/250\n - 4s - loss: 0.9550 - acc: 0.7412 - val_loss: 0.5967 - val_acc: 1.0000\nEpoch 71/250\n - 4s - loss: 0.8753 - acc: 0.7632 - val_loss: 0.5634 - val_acc: 1.0000\nEpoch 72/250\n - 4s - loss: 0.9059 - acc: 0.7237 - val_loss: 0.5349 - val_acc: 1.0000\nEpoch 73/250\n - 3s - loss: 0.8156 - acc: 0.7412 - val_loss: 0.4886 - val_acc: 1.0000\nEpoch 74/250\n - 4s - loss: 0.7387 - acc: 0.7939 - val_loss: 0.4493 - val_acc: 1.0000\nEpoch 75/250\n - 4s - loss: 0.7611 - acc: 0.7368 - val_loss: 0.4174 - val_acc: 1.0000\nEpoch 76/250\n - 3s - loss: 0.6848 - acc: 0.7939 - val_loss: 0.3933 - val_acc: 1.0000\nEpoch 77/250\n - 3s - loss: 0.6633 - acc: 0.8026 - val_loss: 0.3776 - val_acc: 1.0000\nEpoch 78/250\n - 3s - loss: 0.6301 - acc: 0.8246 - val_loss: 0.3275 - val_acc: 1.0000\nEpoch 79/250\n - 3s - loss: 0.6094 - acc: 0.8333 - val_loss: 0.3017 - val_acc: 1.0000\nEpoch 80/250\n - 3s - loss: 0.5595 - acc: 0.8465 - val_loss: 0.2663 - val_acc: 1.0000\nEpoch 81/250\n - 4s - loss: 0.5036 - acc: 0.8596 - val_loss: 0.2345 - val_acc: 1.0000\nEpoch 82/250\n - 4s - loss: 0.5001 - acc: 0.8553 - val_loss: 0.2107 - val_acc: 1.0000\nEpoch 83/250\n - 3s - loss: 0.4545 - acc: 0.8904 - val_loss: 0.1932 - val_acc: 1.0000\nEpoch 84/250\n - 3s - loss: 0.5007 - acc: 0.8728 - val_loss: 0.1803 - val_acc: 1.0000\nEpoch 85/250\n - 4s - loss: 0.4278 - acc: 0.8947 - val_loss: 0.1627 - val_acc: 1.0000\nEpoch 86/250\n - 3s - loss: 0.4448 - acc: 0.8553 - val_loss: 0.1529 - val_acc: 1.0000\nEpoch 87/250\n - 3s - loss: 0.4939 - acc: 0.8465 - val_loss: 0.1509 - val_acc: 1.0000\nEpoch 88/250\n - 3s - loss: 0.4350 - acc: 0.8728 - val_loss: 0.1700 - val_acc: 1.0000\nEpoch 89/250\n - 3s - loss: 0.3581 - acc: 0.9035 - val_loss: 0.1648 - val_acc: 1.0000\nEpoch 90/250\n - 4s - loss: 0.4218 - acc: 0.8772 - val_loss: 0.1490 - val_acc: 1.0000\nEpoch 91/250\n - 3s - loss: 0.3271 - acc: 0.9254 - val_loss: 0.1441 - val_acc: 1.0000\nEpoch 92/250\n - 3s - loss: 0.3888 - acc: 0.8816 - val_loss: 0.1474 - val_acc: 1.0000\nEpoch 93/250\n - 3s - loss: 0.2948 - acc: 0.9254 - val_loss: 0.1498 - val_acc: 1.0000\nEpoch 94/250\n - 3s - loss: 0.2997 - acc: 0.9254 - val_loss: 0.1402 - val_acc: 1.0000\nEpoch 95/250\n - 3s - loss: 0.2726 - acc: 0.9605 - val_loss: 0.1147 - val_acc: 1.0000\nEpoch 96/250\n - 3s - loss: 0.2664 - acc: 0.9474 - val_loss: 0.0994 - val_acc: 1.0000\nEpoch 97/250\n - 3s - loss: 0.2780 - acc: 0.9211 - val_loss: 0.0867 - val_acc: 1.0000\nEpoch 98/250\n - 3s - loss: 0.2456 - acc: 0.9298 - val_loss: 0.0891 - val_acc: 1.0000\nEpoch 99/250\n - 3s - loss: 0.2762 - acc: 0.9254 - val_loss: 0.1038 - val_acc: 1.0000\nEpoch 100/250\n - 4s - loss: 0.2661 - acc: 0.9211 - val_loss: 0.1060 - val_acc: 1.0000\nEpoch 101/250\n - 4s - loss: 0.2527 - acc: 0.9386 - val_loss: 0.0780 - val_acc: 1.0000\nEpoch 102/250\n - 3s - loss: 0.2426 - acc: 0.9474 - val_loss: 0.0557 - val_acc: 1.0000\nEpoch 103/250\n - 3s - loss: 0.1903 - acc: 0.9605 - val_loss: 0.0430 - val_acc: 1.0000\nEpoch 104/250\n - 3s - loss: 0.2456 - acc: 0.9386 - val_loss: 0.0396 - val_acc: 1.0000\nEpoch 105/250\n - 4s - loss: 0.2493 - acc: 0.9430 - val_loss: 0.0469 - val_acc: 1.0000\nEpoch 106/250\n - 4s - loss: 0.1754 - acc: 0.9693 - val_loss: 0.0570 - val_acc: 1.0000\nEpoch 107/250\n - 3s - loss: 0.1763 - acc: 0.9561 - val_loss: 0.0442 - val_acc: 1.0000\nEpoch 108/250\n - 3s - loss: 0.1415 - acc: 0.9605 - val_loss: 0.0328 - val_acc: 1.0000\nEpoch 109/250\n - 4s - loss: 0.1419 - acc: 0.9518 - val_loss: 0.0253 - val_acc: 1.0000\nEpoch 110/250\n - 3s - loss: 0.1513 - acc: 0.9649 - val_loss: 0.0223 - val_acc: 1.0000\nEpoch 111/250\n - 3s - loss: 0.1980 - acc: 0.9430 - val_loss: 0.0241 - val_acc: 1.0000\nEpoch 112/250\n - 3s - loss: 0.1406 - acc: 0.9605 - val_loss: 0.0295 - val_acc: 1.0000\nEpoch 113/250\n - 4s - loss: 0.1248 - acc: 0.9737 - val_loss: 0.0412 - val_acc: 1.0000\nEpoch 114/250\n - 3s - loss: 0.1214 - acc: 0.9781 - val_loss: 0.0455 - val_acc: 1.0000\nEpoch 115/250\n - 5s - loss: 0.1734 - acc: 0.9518 - val_loss: 0.0325 - val_acc: 1.0000\nEpoch 116/250\n - 6s - loss: 0.1393 - acc: 0.9649 - val_loss: 0.0269 - val_acc: 1.0000\nEpoch 117/250\n - 6s - loss: 0.1166 - acc: 0.9825 - val_loss: 0.0232 - val_acc: 1.0000\nEpoch 118/250\n - 4s - loss: 0.0952 - acc: 0.9868 - val_loss: 0.0207 - val_acc: 1.0000\nEpoch 119/250\n - 4s - loss: 0.1168 - acc: 0.9781 - val_loss: 0.0236 - val_acc: 1.0000\nEpoch 120/250\n - 4s - loss: 0.1134 - acc: 0.9693 - val_loss: 0.0322 - val_acc: 1.0000\nEpoch 121/250\n - 4s - loss: 0.1194 - acc: 0.9737 - val_loss: 0.0312 - val_acc: 1.0000\nEpoch 122/250\n - 3s - loss: 0.1258 - acc: 0.9781 - val_loss: 0.0204 - val_acc: 1.0000\nEpoch 123/250\n - 4s - loss: 0.1192 - acc: 0.9605 - val_loss: 0.0142 - val_acc: 1.0000\nEpoch 124/250\n - 4s - loss: 0.1014 - acc: 0.9693 - val_loss: 0.0110 - val_acc: 1.0000\nEpoch 125/250\n - 3s - loss: 0.0883 - acc: 0.9868 - val_loss: 0.0095 - val_acc: 1.0000\nEpoch 126/250\n - 4s - loss: 0.0847 - acc: 0.9737 - val_loss: 0.0087 - val_acc: 1.0000\nEpoch 127/250\n - 3s - loss: 0.1031 - acc: 0.9781 - val_loss: 0.0092 - val_acc: 1.0000\nEpoch 128/250\n - 4s - loss: 0.0806 - acc: 0.9825 - val_loss: 0.0131 - val_acc: 1.0000\nEpoch 129/250\n - 3s - loss: 0.0674 - acc: 0.9956 - val_loss: 0.0198 - val_acc: 1.0000\nEpoch 130/250\n - 4s - loss: 0.1029 - acc: 0.9737 - val_loss: 0.0191 - val_acc: 1.0000\nEpoch 131/250\n - 3s - loss: 0.0854 - acc: 0.9781 - val_loss: 0.0119 - val_acc: 1.0000\nEpoch 132/250\n - 4s - loss: 0.0950 - acc: 0.9737 - val_loss: 0.0078 - val_acc: 1.0000\nEpoch 133/250\n - 4s - loss: 0.0624 - acc: 0.9868 - val_loss: 0.0064 - val_acc: 1.0000\nEpoch 134/250\n - 3s - loss: 0.0667 - acc: 0.9956 - val_loss: 0.0061 - val_acc: 1.0000\nEpoch 135/250\n - 3s - loss: 0.0958 - acc: 0.9825 - val_loss: 0.0057 - val_acc: 1.0000\nEpoch 136/250\n - 4s - loss: 0.0624 - acc: 0.9868 - val_loss: 0.0061 - val_acc: 1.0000\nEpoch 137/250\n - 4s - loss: 0.0487 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\nEpoch 138/250\n - 3s - loss: 0.0787 - acc: 0.9868 - val_loss: 0.0082 - val_acc: 1.0000\nEpoch 139/250\n - 3s - loss: 0.0724 - acc: 0.9781 - val_loss: 0.0077 - val_acc: 1.0000\nEpoch 140/250\n - 3s - loss: 0.0494 - acc: 0.9956 - val_loss: 0.0060 - val_acc: 1.0000\nEpoch 141/250\n - 3s - loss: 0.0539 - acc: 0.9868 - val_loss: 0.0047 - val_acc: 1.0000\nEpoch 142/250\n - 3s - loss: 0.0522 - acc: 0.9956 - val_loss: 0.0045 - val_acc: 1.0000\nEpoch 143/250\n - 3s - loss: 0.0460 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\nEpoch 144/250\n - 3s - loss: 0.0314 - acc: 0.9956 - val_loss: 0.0040 - val_acc: 1.0000\nEpoch 145/250\n - 3s - loss: 0.0934 - acc: 0.9649 - val_loss: 0.0042 - val_acc: 1.0000\nEpoch 146/250\n - 3s - loss: 0.0558 - acc: 0.9912 - val_loss: 0.0042 - val_acc: 1.0000\nEpoch 147/250\n - 3s - loss: 0.0427 - acc: 0.9956 - val_loss: 0.0044 - val_acc: 1.0000\nEpoch 148/250\n - 4s - loss: 0.0492 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\nEpoch 149/250\n - 3s - loss: 0.0635 - acc: 0.9912 - val_loss: 0.0037 - val_acc: 1.0000\nEpoch 150/250\n - 3s - loss: 0.0695 - acc: 0.9825 - val_loss: 0.0032 - val_acc: 1.0000\nEpoch 151/250\n - 4s - loss: 0.0471 - acc: 0.9868 - val_loss: 0.0032 - val_acc: 1.0000\nEpoch 152/250\n - 3s - loss: 0.0424 - acc: 0.9912 - val_loss: 0.0037 - val_acc: 1.0000\nEpoch 153/250\n - 3s - loss: 0.0602 - acc: 0.9825 - val_loss: 0.0042 - val_acc: 1.0000\nEpoch 154/250\n - 4s - loss: 0.0568 - acc: 0.9868 - val_loss: 0.0049 - val_acc: 1.0000\nEpoch 155/250\n - 3s - loss: 0.0211 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\nEpoch 156/250\n - 3s - loss: 0.0553 - acc: 0.9912 - val_loss: 0.0066 - val_acc: 1.0000\nEpoch 157/250\n - 3s - loss: 0.0463 - acc: 0.9912 - val_loss: 0.0058 - val_acc: 1.0000\nEpoch 158/250\n - 3s - loss: 0.0374 - acc: 0.9956 - val_loss: 0.0049 - val_acc: 1.0000\nEpoch 159/250\n - 3s - loss: 0.0342 - acc: 0.9912 - val_loss: 0.0041 - val_acc: 1.0000\nEpoch 160/250\n - 3s - loss: 0.0408 - acc: 0.9956 - val_loss: 0.0032 - val_acc: 1.0000\nEpoch 161/250\n - 3s - loss: 0.0381 - acc: 0.9912 - val_loss: 0.0025 - val_acc: 1.0000\nEpoch 162/250\n - 3s - loss: 0.0362 - acc: 0.9912 - val_loss: 0.0022 - val_acc: 1.0000\nEpoch 163/250\n - 3s - loss: 0.0300 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\nEpoch 164/250\n - 3s - loss: 0.0344 - acc: 0.9956 - val_loss: 0.0021 - val_acc: 1.0000\nEpoch 165/250\n - 4s - loss: 0.0357 - acc: 0.9912 - val_loss: 0.0022 - val_acc: 1.0000\nEpoch 166/250\n - 5s - loss: 0.0392 - acc: 0.9912 - val_loss: 0.0024 - val_acc: 1.0000\nEpoch 167/250\n - 6s - loss: 0.0363 - acc: 0.9912 - val_loss: 0.0025 - val_acc: 1.0000\nEpoch 168/250\n - 5s - loss: 0.0300 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\nEpoch 169/250\n - 4s - loss: 0.0370 - acc: 0.9912 - val_loss: 0.0028 - val_acc: 1.0000\nEpoch 170/250\n - 3s - loss: 0.0396 - acc: 0.9868 - val_loss: 0.0029 - val_acc: 1.0000\nEpoch 171/250\n - 3s - loss: 0.0510 - acc: 0.9825 - val_loss: 0.0032 - val_acc: 1.0000\nEpoch 172/250\n - 4s - loss: 0.0379 - acc: 0.9912 - val_loss: 0.0031 - val_acc: 1.0000\nEpoch 173/250\n - 3s - loss: 0.0317 - acc: 0.9912 - val_loss: 0.0029 - val_acc: 1.0000\nEpoch 174/250\n - 4s - loss: 0.0189 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\nEpoch 175/250\n - 3s - loss: 0.0369 - acc: 0.9868 - val_loss: 0.0021 - val_acc: 1.0000\nEpoch 176/250\n - 3s - loss: 0.0430 - acc: 0.9868 - val_loss: 0.0016 - val_acc: 1.0000\nEpoch 177/250\n - 4s - loss: 0.0266 - acc: 0.9956 - val_loss: 0.0013 - val_acc: 1.0000\nEpoch 178/250\n - 4s - loss: 0.0419 - acc: 0.9912 - val_loss: 0.0011 - val_acc: 1.0000\nEpoch 179/250\n - 3s - loss: 0.0393 - acc: 0.9868 - val_loss: 0.0010 - val_acc: 1.0000\nEpoch 180/250\n - 3s - loss: 0.0313 - acc: 0.9956 - val_loss: 0.0010 - val_acc: 1.0000\nEpoch 181/250\n - 4s - loss: 0.0302 - acc: 0.9912 - val_loss: 0.0013 - val_acc: 1.0000\nEpoch 182/250\n - 4s - loss: 0.0493 - acc: 0.9825 - val_loss: 0.0018 - val_acc: 1.0000\nEpoch 183/250\n - 3s - loss: 0.0227 - acc: 0.9956 - val_loss: 0.0024 - val_acc: 1.0000\nEpoch 184/250\n - 4s - loss: 0.0274 - acc: 0.9956 - val_loss: 0.0021 - val_acc: 1.0000\nEpoch 185/250\n - 4s - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\nEpoch 186/250\n - 3s - loss: 0.0195 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\nEpoch 187/250\n - 4s - loss: 0.0310 - acc: 0.9956 - val_loss: 0.0014 - val_acc: 1.0000\nEpoch 188/250\n - 4s - loss: 0.0306 - acc: 0.9956 - val_loss: 0.0012 - val_acc: 1.0000\nEpoch 189/250\n - 4s - loss: 0.0172 - acc: 0.9956 - val_loss: 0.0012 - val_acc: 1.0000\nEpoch 190/250\n - 3s - loss: 0.0253 - acc: 0.9956 - val_loss: 0.0012 - val_acc: 1.0000\nEpoch 191/250\n - 4s - loss: 0.0209 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\nEpoch 192/250\n - 3s - loss: 0.0186 - acc: 0.9956 - val_loss: 0.0012 - val_acc: 1.0000\nEpoch 193/250\n - 3s - loss: 0.0266 - acc: 0.9912 - val_loss: 0.0015 - val_acc: 1.0000\nEpoch 194/250\n - 3s - loss: 0.0205 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\nEpoch 195/250\n - 4s - loss: 0.0304 - acc: 0.9956 - val_loss: 0.0022 - val_acc: 1.0000\nEpoch 196/250\n - 3s - loss: 0.0176 - acc: 0.9956 - val_loss: 0.0021 - val_acc: 1.0000\nEpoch 197/250\n - 3s - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\nEpoch 198/250\n - 4s - loss: 0.0213 - acc: 0.9956 - val_loss: 0.0019 - val_acc: 1.0000\nEpoch 199/250\n - 3s - loss: 0.0144 - acc: 0.9956 - val_loss: 0.0019 - val_acc: 1.0000\nEpoch 200/250\n - 3s - loss: 0.0309 - acc: 0.9912 - val_loss: 0.0020 - val_acc: 1.0000\nEpoch 201/250\n - 3s - loss: 0.0289 - acc: 0.9912 - val_loss: 0.0016 - val_acc: 1.0000\nEpoch 202/250\n - 4s - loss: 0.0200 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\nEpoch 203/250\n - 4s - loss: 0.0168 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\nEpoch 204/250\n - 3s - loss: 0.0246 - acc: 0.9956 - val_loss: 9.3211e-04 - val_acc: 1.0000\nEpoch 205/250\n - 4s - loss: 0.0343 - acc: 0.9956 - val_loss: 8.6199e-04 - val_acc: 1.0000\nEpoch 206/250\n - 3s - loss: 0.0269 - acc: 0.9956 - val_loss: 7.3758e-04 - val_acc: 1.0000\nEpoch 207/250\n - 3s - loss: 0.0297 - acc: 0.9912 - val_loss: 6.9015e-04 - val_acc: 1.0000\nEpoch 208/250\n - 4s - loss: 0.0157 - acc: 1.0000 - val_loss: 7.5702e-04 - val_acc: 1.0000\nEpoch 209/250\n - 3s - loss: 0.0226 - acc: 0.9956 - val_loss: 8.2171e-04 - val_acc: 1.0000\nEpoch 210/250\n - 3s - loss: 0.0148 - acc: 0.9956 - val_loss: 8.2034e-04 - val_acc: 1.0000\nEpoch 211/250\n - 3s - loss: 0.0092 - acc: 1.0000 - val_loss: 8.2052e-04 - val_acc: 1.0000\nEpoch 212/250\n - 3s - loss: 0.0147 - acc: 1.0000 - val_loss: 7.1420e-04 - val_acc: 1.0000\nEpoch 213/250\n - 3s - loss: 0.0142 - acc: 1.0000 - val_loss: 5.7892e-04 - val_acc: 1.0000\nEpoch 214/250\n - 3s - loss: 0.0150 - acc: 1.0000 - val_loss: 4.7764e-04 - val_acc: 1.0000\nEpoch 215/250\n - 3s - loss: 0.0083 - acc: 1.0000 - val_loss: 4.1289e-04 - val_acc: 1.0000\nEpoch 216/250\n - 4s - loss: 0.0260 - acc: 0.9912 - val_loss: 4.5909e-04 - val_acc: 1.0000\nEpoch 217/250\n - 5s - loss: 0.0177 - acc: 1.0000 - val_loss: 5.4084e-04 - val_acc: 1.0000\nEpoch 218/250\n - 6s - loss: 0.0173 - acc: 0.9956 - val_loss: 6.9447e-04 - val_acc: 1.0000\nEpoch 219/250\n - 6s - loss: 0.0116 - acc: 1.0000 - val_loss: 9.4839e-04 - val_acc: 1.0000\nEpoch 220/250\n - 3s - loss: 0.0145 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\nEpoch 221/250\n - 4s - loss: 0.0327 - acc: 0.9825 - val_loss: 0.0010 - val_acc: 1.0000\nEpoch 222/250\n - 3s - loss: 0.0138 - acc: 1.0000 - val_loss: 7.5709e-04 - val_acc: 1.0000\nEpoch 223/250\n - 3s - loss: 0.0170 - acc: 0.9912 - val_loss: 5.4731e-04 - val_acc: 1.0000\nEpoch 224/250\n - 4s - loss: 0.0098 - acc: 1.0000 - val_loss: 4.4306e-04 - val_acc: 1.0000\nEpoch 225/250\n - 3s - loss: 0.0090 - acc: 1.0000 - val_loss: 3.8437e-04 - val_acc: 1.0000\nEpoch 226/250\n - 3s - loss: 0.0168 - acc: 0.9956 - val_loss: 3.8987e-04 - val_acc: 1.0000\nEpoch 227/250\n - 3s - loss: 0.0076 - acc: 1.0000 - val_loss: 4.0113e-04 - val_acc: 1.0000\nEpoch 228/250\n - 3s - loss: 0.0195 - acc: 0.9912 - val_loss: 4.5326e-04 - val_acc: 1.0000\nEpoch 229/250\n - 3s - loss: 0.0145 - acc: 0.9956 - val_loss: 4.8800e-04 - val_acc: 1.0000\nEpoch 230/250\n - 4s - loss: 0.0132 - acc: 1.0000 - val_loss: 5.1701e-04 - val_acc: 1.0000\nEpoch 231/250\n - 3s - loss: 0.0204 - acc: 0.9956 - val_loss: 4.6637e-04 - val_acc: 1.0000\nEpoch 232/250\n - 3s - loss: 0.0113 - acc: 1.0000 - val_loss: 3.9314e-04 - val_acc: 1.0000\nEpoch 233/250\n - 4s - loss: 0.0117 - acc: 1.0000 - val_loss: 3.3140e-04 - val_acc: 1.0000\nEpoch 234/250\n - 4s - loss: 0.0149 - acc: 0.9956 - val_loss: 2.7082e-04 - val_acc: 1.0000\nEpoch 235/250\n - 4s - loss: 0.0134 - acc: 1.0000 - val_loss: 2.4914e-04 - val_acc: 1.0000\nEpoch 236/250\n - 4s - loss: 0.0249 - acc: 0.9912 - val_loss: 2.4635e-04 - val_acc: 1.0000\nEpoch 237/250\n - 4s - loss: 0.0112 - acc: 1.0000 - val_loss: 2.6499e-04 - val_acc: 1.0000\nEpoch 238/250\n - 3s - loss: 0.0105 - acc: 0.9956 - val_loss: 2.8929e-04 - val_acc: 1.0000\nEpoch 239/250\n - 3s - loss: 0.0194 - acc: 1.0000 - val_loss: 3.9391e-04 - val_acc: 1.0000\nEpoch 240/250\n - 4s - loss: 0.0110 - acc: 1.0000 - val_loss: 5.3074e-04 - val_acc: 1.0000\nEpoch 241/250\n - 3s - loss: 0.0100 - acc: 1.0000 - val_loss: 6.9979e-04 - val_acc: 1.0000\nEpoch 242/250\n - 3s - loss: 0.0114 - acc: 1.0000 - val_loss: 8.8504e-04 - val_acc: 1.0000\nEpoch 243/250\n - 3s - loss: 0.0142 - acc: 0.9956 - val_loss: 0.0010 - val_acc: 1.0000\nEpoch 244/250\n - 3s - loss: 0.0173 - acc: 0.9956 - val_loss: 0.0012 - val_acc: 1.0000\nEpoch 245/250\n - 3s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\nEpoch 246/250\n - 3s - loss: 0.0189 - acc: 0.9912 - val_loss: 0.0010 - val_acc: 1.0000\nEpoch 247/250\n - 4s - loss: 0.0086 - acc: 1.0000 - val_loss: 7.7833e-04 - val_acc: 1.0000\nEpoch 248/250\n - 3s - loss: 0.0182 - acc: 0.9956 - val_loss: 5.5676e-04 - val_acc: 1.0000\nEpoch 249/250\n - 4s - loss: 0.0229 - acc: 0.9956 - val_loss: 3.9937e-04 - val_acc: 1.0000\nEpoch 250/250\n - 4s - loss: 0.0127 - acc: 1.0000 - val_loss: 3.2217e-04 - val_acc: 1.0000\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["scor = cnn_model.evaluate( np.array(x_test),  np.array(y_test), verbose=0)\n\nprint('test los {:.4f}'.format(scor[0]))\nprint('test acc {:.4f}'.format(scor[1]))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">test los 0.3462\ntest acc 0.9375\n</div>"]}}],"execution_count":8}],"metadata":{"name":"face_recognition","notebookId":2061541566367649},"nbformat":4,"nbformat_minor":0}
